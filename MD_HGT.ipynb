{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QligFEP benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ArgumentError",
     "evalue": "Python argument types in\n    SDMolSupplier.__init__(SDMolSupplier, _io.TextIOWrapper)\ndid not match C++ signature:\n    __init__(_object*, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > fileName, bool sanitize=True, bool removeHs=True, bool strictParsing=True)\n    __init__(_object*)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArgumentError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-deb84cbba264>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m#    target = sdf.split('\\\\')[-1].split('_ligands')[0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0msdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'./MoleculasDocking/Working/sdf_no-coord/mols_working_41k.sdf'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0msuppl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mChem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSDMolSupplier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0mfp_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMFP_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuppl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mname_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetProp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_Name'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuppl\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mArgumentError\u001b[0m: Python argument types in\n    SDMolSupplier.__init__(SDMolSupplier, _io.TextIOWrapper)\ndid not match C++ signature:\n    __init__(_object*, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > fileName, bool sanitize=True, bool removeHs=True, bool strictParsing=True)\n    __init__(_object*)"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import itertools\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import Chem\n",
    "from rdkit.DataStructs import FingerprintSimilarity\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "def MFP_matrix(mol_list):\n",
    "    fp = [AllChem.GetMorganFingerprintAsBitVect(mol, 2) for mol in mol_list]\n",
    "    mfps = list(FingerprintSimilarity(x, y) for x, y in itertools.product(fp, repeat=2))\n",
    "    return fp, np.array(mfps).reshape(len(fp), len(fp))\n",
    "\n",
    "target_data = {}\n",
    "target_labels = []\n",
    "#for sdf in glob.glob('{}/MoleculasDocking/Working/sdf_no-coord/*.sdf'.format(os.getcwd())):\n",
    "#    target = sdf.split('\\\\')[-1].split('_ligands')[0]\n",
    "sdf = open ('./MoleculasDocking/Working/sdf_no-coord/mols_working_41k.sdf', 'r')\n",
    "suppl = Chem.SDMolSupplier(sdf)\n",
    "fp_list, fp_mat = MFP_matrix(suppl)\n",
    "name_list = [mol.GetProp('_Name') for mol in suppl]\n",
    "target_data[target] = {}\n",
    "target_data[target]['fp_list'] = fp_list\n",
    "target_data[target]['name_list'] = name_list\n",
    "target_labels.extend([target] * len(suppl))\n",
    "\n",
    "fps = [target_data[targ]['fp_list'] for targ in target_data.keys()]\n",
    "flat_fps = np.array([fp for target in fps for fp in target])\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "pca_coords = pca.fit_transform(flat_fps)\n",
    "\n",
    "# Apply k-means clustering\n",
    "num_clusters = 20  # Number of clusters\n",
    "kmeans = KMeans(n_clusters=num_clusters)\n",
    "kmeans.fit(pca_coords)\n",
    "cluster_labels = kmeans.labels_\n",
    "\n",
    "fig = plt.figure(figsize=(18, 8))\n",
    "X = [i[0] for i in pca_coords]  \n",
    "Y = [i[1] for i in pca_coords]  \n",
    "markers = ['.', 'x']\n",
    "k = 0\n",
    "for target in target_data.keys():  \n",
    "    k += 1\n",
    "    if k <= 8:\n",
    "        m = markers[0]\n",
    "    else:\n",
    "        m = markers[1]\n",
    "    indices = [i for i, target_label in enumerate(target_labels) if target_label == target]\n",
    "    targ_x = [X[i] for i in indices]\n",
    "    targ_y = [Y[i] for i in indices]\n",
    "    cluster_label = cluster_labels[indices[0]]  \n",
    "    color = cm.tab20(cluster_label)  #Color\n",
    "    plt.scatter(targ_x, targ_y, label=target, marker=m, color=color)\n",
    "\n",
    "# Plot cluster centroids\n",
    "centroids = kmeans.cluster_centers_\n",
    "plt.scatter(centroids[:, 0], centroids[:, 1], marker='o', color='black', s=150, label='Centroids')\n",
    "\n",
    "plt.title('PCA with K-means Clustering')\n",
    "plt.xlabel('PCA {}%'.format(round(pca.explained_variance_ratio_[0] * 100, 2)))\n",
    "plt.ylabel('PCA {}%'.format(round(pca.explained_variance_ratio_[1] * 100, 2)))\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "centroids = kmeans.cluster_centers_\n",
    "plt.scatter(centroids[:, 0], centroids[:, 1], marker='o', color='black', s=150, label='Centroids')\n",
    "\n",
    "# Find the closest molecule to each centroid\n",
    "f = open ('./MoleculasDocking/Working/20-centroids.txt', 'w')\n",
    "for i, centroid in enumerate(centroids):\n",
    "\n",
    "    cluster_label = i\n",
    "    name = './MoleculasDocking/Working/cluster'+str(i)+'.txt'\n",
    "    c = open (name, 'w')\n",
    "    cluster_indices = [index for index, label in enumerate(cluster_labels) if label == cluster_label]\n",
    "    cluster_mols = [target_data[target_labels[index]]['name_list'][0] for index in cluster_indices]\n",
    "    for i in range(len(cluster_mols)):\n",
    "        print(f\"{cluster_mols[i]}\", file=c)\n",
    "    \n",
    "    closest_mol_index = min(cluster_indices, key=lambda x: np.linalg.norm(pca_coords[x] - centroid))\n",
    "    closest_mol_name = target_data[target_labels[closest_mol_index]]['name_list'][0]\n",
    "    print(closest_mol_name, file=f)\n",
    "    plt.text(centroid[0], centroid[1], closest_mol_name, color='red', fontsize=10)\n",
    "\n",
    "plt.title('PCA with K-means Clustering')\n",
    "plt.xlabel('PCA {}%'.format(round(pca.explained_variance_ratio_[0] * 100, 2)))\n",
    "plt.ylabel('PCA {}%'.format(round(pca.explained_variance_ratio_[1] * 100, 2)))\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_clusters = 120  # Número máximo de Clusters\n",
    "sse = []  # Sum of squared errors\n",
    "k_values = range(1, max_clusters + 1)\n",
    "\n",
    "for k in k_values:\n",
    "    kmeans = KMeans(n_clusters=k)\n",
    "    kmeans.fit(pca_coords)\n",
    "    sse.append(kmeans.inertia_)  \n",
    "\n",
    "# Plot the elbow curve\n",
    "plt.plot(k_values, sse, 'bx-')\n",
    "plt.xlabel('Number of Clusters (k)')\n",
    "plt.ylabel('Sum of Squared Errors (SSE)')\n",
    "plt.title('Elbow Method')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import itertools\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import Chem\n",
    "from rdkit.DataStructs import FingerprintSimilarity\n",
    "import numpy as np\n",
    "\n",
    "def MFP_matrix(mol_list):\n",
    "    fp = [AllChem.GetMorganFingerprintAsBitVect(mol, 2) for mol in mol_list]\n",
    "    mfps = list(FingerprintSimilarity(x, y) for x, y in itertools.product(fp, repeat=2))\n",
    "    return fp, np.array(mfps).reshape(len(fp), len(fp))\n",
    "\n",
    "target_data = {}\n",
    "target_labels = []\n",
    "for sdf in glob.glob('{}/Selected_Docking/Working2/*.sdf'.format(os.getcwd())):\n",
    "    target = sdf.split('\\\\')[-1].split('_ligands')[0]\n",
    "    suppl = Chem.SDMolSupplier(sdf)\n",
    "    fp_list, fp_mat = MFP_matrix(suppl)\n",
    "    name_list = [mol.GetProp('_Name') for mol in suppl]\n",
    "    target_data[target] = {}\n",
    "    target_data[target]['fp_list'] = fp_list\n",
    "    target_data[target]['name_list'] = name_list\n",
    "    target_labels.extend([target] * len(suppl))\n",
    "\n",
    "\n",
    "fps = [target_data[targ]['fp_list'] for targ in target_data.keys()]\n",
    "flat_fps =  np.array([fp for target in fps for fp in target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "pca = PCA(n_components=2)\n",
    "pca_coords = pca.fit_transform(flat_fps)\n",
    "fig = plt.figure(figsize=(18, 8))\n",
    "X = [i[0] for i in pca_coords] #X axis\n",
    "Y = [i[1] for i in pca_coords] #Y axis\n",
    "markers = ['.', 'x']\n",
    "k = 0\n",
    "for target in target_data.keys(): #iterate over targets \n",
    "    k += 1\n",
    "    if k <= 8:\n",
    "        m = markers[0]\n",
    "    else:\n",
    "        m = markers[1]\n",
    "    indices = [i for i, target_label in enumerate(target_labels) if target_label == target]\n",
    "    targ_x = [X[i] for i in indices]\n",
    "    targ_y = [Y[i] for i in indices]\n",
    "    plt.scatter(targ_x, targ_y, label = target, marker=m)\n",
    "    \n",
    "#plt.legend(loc='right', bbox_to_anchor=(1.3, 0.5))\n",
    "plt.title('PCA all')\n",
    "plt.xlabel('PCA {}%'.format(round(pca.explained_variance_ratio_[0]*100, 2)))\n",
    "plt.ylabel('PCA {}%'.format(round(pca.explained_variance_ratio_[1]*100, 2)))\n",
    "plt.grid()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "tsne = TSNE(n_components=2, random_state=0)\n",
    "tx = tsne.fit_transform(flat_fps)\n",
    "fig = plt.figure(figsize=(18, 8))\n",
    "X = [i[0] for i in tx] #X axis\n",
    "Y = [i[1] for i in tx] #Y axis\n",
    "k = 0\n",
    "for target in target_data.keys(): #iterate over targets \n",
    "    k += 1\n",
    "    if k <= 8:\n",
    "        m = markers[0]\n",
    "    else:\n",
    "        m = markers[1]\n",
    "    indices = [i for i, target_label in enumerate(target_labels) if target_label == target]\n",
    "    targ_x = [X[i] for i in indices]\n",
    "    targ_y = [Y[i] for i in indices]\n",
    "    plt.scatter(targ_x, targ_y, label = target, marker=m)\n",
    "    \n",
    "plt.legend(loc='right', bbox_to_anchor=(1.3, 0.5))\n",
    "plt.title('t-SNE all')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap.umap_ as umap\n",
    "import umap.plot\n",
    "import matplotlib.cm as cm\n",
    "fit = umap.UMAP(\n",
    "        n_neighbors=15,\n",
    "        min_dist=0.15,\n",
    "        n_components=3,\n",
    "        random_state=42\n",
    "    )\n",
    "u = fit.fit_transform(flat_fps)\n",
    "fig = plt.figure(figsize=(18, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "X = [i[0] for i in u] #X axis\n",
    "Y = [i[1] for i in u] #Y axis \n",
    "Z = [i[2] for i in u] #Z axis\n",
    "markers = ['.', 'x']\n",
    "k = -1\n",
    "colors = itertools.cycle(cm.tab10(np.linspace(0, 1, 8)))\n",
    "for target, c in zip(target_data.keys(), colors): #iterate over targets\n",
    "    k += 1\n",
    "    if k < 8:\n",
    "        m = markers[0]\n",
    "    else:\n",
    "        m = markers[1]\n",
    "    indices = [i for i, target_label in enumerate(target_labels) if target_label == target]\n",
    "    targ_x = [X[i] for i in indices]\n",
    "    targ_y = [Y[i] for i in indices]\n",
    "    targ_z = [Z[i] for i in indices]\n",
    "    ax.scatter(targ_x, targ_y, targ_z, marker=m, s=75, color=c, label=target, alpha=0.75)\n",
    "    if target in ['PTP1B', 'hif2a', 'CDK2']:\n",
    "        ax.text(np.mean(targ_x), np.mean(targ_y), np.mean(targ_z) + 1, target, size=15)\n",
    "    else:   \n",
    "        ax.text(np.mean(targ_x) - 2, np.mean(targ_y), np.mean(targ_z) - 5, target, size=15)\n",
    "\n",
    "plt.legend(loc='right', bbox_to_anchor=(1.3, 0.5))\n",
    "plt.xlabel('UMAP_0', fontsize=18)\n",
    "plt.ylabel('UMAP_1', fontsize=18)\n",
    "ax.set_zlabel('UMAP_2', fontsize=18)\n",
    "plt.title('UMAP 3D embedding of the chemical space', fontsize=18)\n",
    "plt.savefig('plots/UMAP.svg', dpi=300)\n",
    "plt.savefig('plots/UMAP.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Seed uniform distribution.\n",
    "#### The random seeds where generated with the function $RANDOM which returns a different random integer at each invocation.\n",
    "#### Nominal range: 0 - 32767 (signed 16-bit integer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "summary_dict = {}\n",
    "seeds = []\n",
    "for forcefield in ['OPLS2015', 'openFF2', 'openFF']:\n",
    "    summary_dict[forcefield] = {}\n",
    "    for file in glob.glob(os.getcwd() + '/results/summary_files/{}/*/*/Summary*'.format(forcefield)):\n",
    "        target, leg = file.split('/')[-3], file.split('/')[-2]\n",
    "        if target not in summary_dict[forcefield].keys():\n",
    "            summary_dict[forcefield][target] = {'protein':{}, 'water':{}}\n",
    "        summary_dict[forcefield][target][leg] = pd.read_csv(file)\n",
    "        seeds.extend(summary_dict[forcefield][target][leg]['seed    '].tolist())\n",
    "        starting_time = [pd.to_datetime(slice.split()[3]) for slice in summary_dict[forcefield][target][leg]['starting time'].tolist()]\n",
    "        ending_time = [pd.to_datetime(slice.split()[3]) for slice in summary_dict[forcefield][target][leg]['ending time'].tolist()]\n",
    "        summary_dict[forcefield][target][leg]['running_time'] = [(x - y) for x, y in zip(ending_time, starting_time)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for example\n",
    "summary_dict['OPLS2015']['CDK2']['protein'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimation of mean running time for protein and water leg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "running_time = {}\n",
    "for leg in ['protein', 'water']:\n",
    "    running_time[leg] = []\n",
    "    for forcefield in summary_dict.keys():\n",
    "        for target in summary_dict[forcefield].keys():\n",
    "            running_time[leg].extend(summary_dict[forcefield][target][leg]['running_time'].tolist())\n",
    "\n",
    "    running_time[leg] = [td for td in running_time[leg] if td.seconds >= 3600]        \n",
    "    running_time[leg] = [td.seconds / 3600 for td in running_time[leg]]\n",
    "\n",
    "plt.hist(running_time['protein'], bins=30, label='protein', alpha=0.5);\n",
    "plt.hist(running_time['water'], bins=30, label='water', alpha=0.5);\n",
    "plt.axvline(np.mean(running_time['protein']), color='teal', linestyle='dashed', linewidth=1, label='protein mean');\n",
    "plt.axvline(np.mean(running_time['water']), color='red', linestyle='dashed', linewidth=1, label='water mean');\n",
    "plt.xlabel('Hours')\n",
    "plt.xlim(1, 3);\n",
    "plt.title('Distribution of Job Wall-clock time estimates')\n",
    "plt.legend()\n",
    "print('Protein leg mean ~{:.3f}h'.format(np.mean(running_time['protein'])))\n",
    "print('Water leg mean ~{:.3f}h'.format(np.mean(running_time['water'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimation of mean standard error of the means for protein and water leg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sems = {}\n",
    "for leg in ['protein', 'water']:\n",
    "    sems[leg] = []\n",
    "    for forcefield in summary_dict.keys():\n",
    "        for target in summary_dict[forcefield].keys():\n",
    "            if target in ['cdk8', 'cmet', 'eg5', 'hif2a', 'pfkfb3', 'shp2', 'syk', 'tnks2']:\n",
    "                benchmark = 'Merck'\n",
    "            else:\n",
    "                benchmark = 'JACS'\n",
    "            tarfile = glob.glob('{}/data/{}/{}/*{}/benchmark/2fs/{}*.txt'.format(os.getcwd(), benchmark, forcefield, target, leg))[0]\n",
    "            with open(tarfile, 'r') as infile:\n",
    "                for line in infile:\n",
    "                    line = line.split()\n",
    "                    if line[0] == 'FEP':\n",
    "                        continue\n",
    "                    else:\n",
    "                        if 'nan' == line[2]:\n",
    "                            continue\n",
    "                        else:\n",
    "                            sems[leg].append(float(line[2]))\n",
    "\n",
    "plt.hist(sems['protein'], bins=30, label='protein', alpha=0.5);\n",
    "plt.hist(sems['water'], bins=30, label='water', alpha=0.5);\n",
    "plt.axvline(np.mean(sems['protein']), color='teal', linestyle='dashed', linewidth=1, label='protein mean');\n",
    "plt.axvline(np.mean(sems['water']), color='red', linestyle='dashed', linewidth=1, label='water mean');\n",
    "plt.xlabel('SEM(kcal/mol)')\n",
    "plt.xlim(0.0, 2.5);\n",
    "plt.title('Distribution of SEM (kcal/mol) for both protein and water legs')\n",
    "plt.legend()\n",
    "print('Protein leg mean ~{:.3f} (kcal/mol)'.format(np.mean(sems['protein'])))\n",
    "print('Water leg mean ~{:.3f} (kcal/mol)'.format(np.mean(sems['water'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(seeds, color = 'blue', edgecolor = 'black', bins = 100);\n",
    "plt.title('Uniform distribution of random seeds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results_dir = os.getcwd() + '/results/old_results'\n",
    "#results_dir = os.getcwd() + '/results/new_results'\n",
    "#results_dir = os.getcwd() + '/results/new_results_2'\n",
    "#results_dir = os.getcwd() + '/results/merged_results'\n",
    "\n",
    "results = {}\n",
    "for benchmark in ['1.JACS', 'Merck']:\n",
    "    results[benchmark] = {}\n",
    "    targets = glob.glob('{}/{}/*'.format(results_dir, benchmark))\n",
    "    for target in targets:\n",
    "        name = target.split('/')[-1]\n",
    "        results[benchmark][name] = {}\n",
    "        for method in ['FEP+_5ns', 'openFF', 'openFF2', 'OPLS2015']:\n",
    "            results[benchmark][name][method] = {'ddG':{}, 'dG':{}}\n",
    "            r = results[benchmark][name][method]\n",
    "            r['ddG'] = pd.read_csv('{}/{}/{}_ddG.csv'.format(target, method, name))\n",
    "            r['ddG']['error'] = r['ddG']['Exp. ddG'] - r['ddG']['Pred. ddG']\n",
    "            r['dG'] = pd.read_csv('{}/{}/{}_dG.csv'.format(target, method, name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#for target in ['Tyk2', 'p38', 'JNK1', 'CDK2', 'PTP1B', 'MCL1', 'Thrombin', 'BACE']:\n",
    "for target in ['7.Tyk2']:\n",
    "    for method in ['cresset_valid', 'amber', 'gaff', 'cgenff', 'consensus']:\n",
    "        results['1.JACS'][target][method] = {'ddG':{}, 'dG':{}}\n",
    "        name = target\n",
    "        df = pd.read_excel('results/final_results_all.xlsx', engine='openpyxl', sheet_name='{}'.format(name))\n",
    "        df = df[['#Ligand', 'dGexptl', '{}'.format(method)]]\n",
    "        df.rename(columns={'#Ligand': 'Ligand', 'dGexptl': 'Exp. dG', '{}'.format(method):'Pred. dG'}, inplace=True)\n",
    "        df['CCC_Error'] = 0\n",
    "        results['1.JACS'][target][method]['dG'] = df.iloc[:-1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "def pearsonr_ci(x, y, alpha=0.05):\n",
    "    ''' calculate Pearson correlation along with the confidence interval using scipy and numpy\n",
    "    Parameters\n",
    "    ----------\n",
    "    x, y : iterable object such as a list or np.array\n",
    "    Input for correlation calculation\n",
    "    alpha : float\n",
    "    Significance level. 0.05 by default\n",
    "    Returns\n",
    "    -------\n",
    "    r : float\n",
    "    Pearson's correlation coefficient\n",
    "    pval : float\n",
    "    The corresponding p value\n",
    "    lo, hi : float\n",
    "    The lower and upper bound of confidence intervals\n",
    "    '''\n",
    "\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    r, p = stats.pearsonr(x, y)\n",
    "    r_z = np.arctanh(r)\n",
    "    se = 1 / np.sqrt(x.size - 3)\n",
    "    z = stats.norm.ppf(1 - alpha / 2)\n",
    "    lo_z, hi_z = r_z - z * se, r_z + z * se\n",
    "    lo, hi = np.tanh((lo_z, hi_z))\n",
    "    return r, p, lo, hi\n",
    "\n",
    "def rmse(targets, predictions):\n",
    "    'calculate root mean square error between array of targets and predictions'\n",
    "    return np.sqrt(((np.array(predictions) - np.array(targets)) ** 2).mean())\n",
    "\n",
    "def analysis(X, Y, Z):\n",
    "    'Returns statistics for correlation between arrays of targets and predictions'\n",
    "    X = [float(x) for x in X]\n",
    "    Y = [float(x) for x in Y]\n",
    "    Z = [float(x) for x in Z]\n",
    "    n_size = int(len(X) * 0.95)\n",
    "    bstp = {'MCC': [], 'MAE': [], 'RMSE': [], 'k_tau': [], 'r':[], 'r2': [], 'lo': [], 'hi': [], 'p_value': [], 'SEM': []}\n",
    "    data = np.column_stack((X, Y, Z))\n",
    "    n = len(X)\n",
    "    if n > 2:\n",
    "        slope, intercept, _, p_value, std_err = stats.linregress(X, Y)\n",
    "        regr = [(slope * x + intercept) for x in X]\n",
    "        rho, _ = stats.spearmanr(X, Y)\n",
    "        for i in range(100):\n",
    "            sampl = resample(data, n_samples=n_size, random_state=i)\n",
    "            X = [i[0] for i in sampl]\n",
    "            Y = [i[1] for i in sampl]\n",
    "            Z = [i[2] for i in sampl]\n",
    "            X2 = np.sign(X)\n",
    "            Y2 = np.sign(Y)\n",
    "            if all(i < 0 for i in X2) and all(j < 0 for j in Y2):\n",
    "                MCC = 0.0\n",
    "            else:\n",
    "                bstp['MCC'].append(matthews_corrcoef(X2, Y2))\n",
    "            bstp['MAE'].append(mean_absolute_error(X, Y))\n",
    "            bstp['RMSE'].append(rmse(X, Y))\n",
    "            bstp['k_tau'].append(stats.kendalltau(X, Y)[0])\n",
    "            bstp['p_value'].append(stats.kendalltau(X, Y)[1])\n",
    "            r, _, lo, hi = pearsonr_ci(X, Y)\n",
    "            bstp['lo'].append(lo**2)\n",
    "            bstp['hi'].append(hi**2)\n",
    "            bstp['r'].append(r)\n",
    "            bstp['r2'].append(r**2)\n",
    "            bstp['SEM'].append(np.mean(Z))\n",
    "    \n",
    "        metrics = {'MCC': [], 'MAE': [], 'RMSE': [], 'sp_rho': rho, 'k_tau': [], 'r':[], 'r2': [], 'lo': [], 'hi': [], 'p_value': [], 'slope': slope, 'intercept': intercept, \"n\": n, \"reg\": regr, 'SEM': []}\n",
    "        for k, v in bstp.items():\n",
    "            metrics[k].append(round(np.mean(v), 2))\n",
    "            metrics[k].append(round(np.std(v), 2))\n",
    "        \n",
    "        for k, v in metrics.items():\n",
    "            try:\n",
    "                metrics[k] = round(v, 2)\n",
    "            except TypeError:\n",
    "                continue\n",
    "        return metrics\n",
    "\n",
    "def linplot(include, d, method):\n",
    "    targs = []\n",
    "    preds = []\n",
    "    sems = []\n",
    "    k = 0\n",
    "    markers = ['s', 'o']\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=2, gridspec_kw={'width_ratios': [4, 1]}, figsize=(12,10), facecolor='white')\n",
    "    ax[1].axis('off')\n",
    "    if d == 'ddG':\n",
    "        type = 'relat'\n",
    "        ax[0].set_xlim(-8, 8)\n",
    "        ax[0].set_ylim(-8, 8)\n",
    "        ax[0].plot((-8, 8), (-8, 8), color='black')\n",
    "        ax[0].plot((-8, 7), (-7, 8), color='black', linestyle='--', alpha=0.7)\n",
    "        ax[0].plot((-7, 8), (-8, 7), color='black', linestyle='--', alpha=0.7)\n",
    "        ax[0].plot((-8, 6), (-6, 8), color='black', linestyle='-.', alpha=0.7)\n",
    "        ax[0].plot((-6, 8), (-8, 6), color='black', linestyle='-.', alpha=0.7)\n",
    "    elif d == 'dG':\n",
    "        type = 'abs'\n",
    "        ax[0].set_xlim(-16, -2)\n",
    "        ax[0].set_ylim(-16, -2)\n",
    "        ax[0].plot((-18, 0), (-18, 0), color='black')\n",
    "        ax[0].plot((-18, -2), (-17, -1), color='black', linestyle='--', alpha=0.7)\n",
    "        ax[0].plot((-17, -1), (-18, -2), color='black', linestyle='--', alpha=0.7)\n",
    "        ax[0].plot((-18, -3), (-16, -1), color='black', linestyle='-.', alpha=0.7)\n",
    "        ax[0].plot((-16, -1), (-18, -3), color='black', linestyle='-.', alpha=0.7)\n",
    "    ax[0].set_xlabel('{} exp [$kcal mol^{}$]'.format(d, -1), fontsize=24)\n",
    "    ax[0].set_ylabel('{} pred [$kcal mol^{}$]'.format(d, -1), fontsize=24)\n",
    "    ax[0].tick_params(axis='both', which='major', labelsize=16)\n",
    "    with open('plots/{}_{}_linplot_data.txt'.format(d, method), 'w') as outfile:\n",
    "        if type == 'relat':\n",
    "            outfile.write('{},{},{},{},{}\\n'.format('Ligand_1', 'Ligand_2', 'Pred. ddG', 'Exp. ddG', 'CCC error'))\n",
    "        else:\n",
    "            outfile.write('{},{},{},{}\\n'.format('Ligand', 'Pred. dG', 'Exp. dG', 'CCC path error'))\n",
    "        for benchmark in results.keys():\n",
    "            for target in results[benchmark].keys():\n",
    "                if include == ['All']:\n",
    "                    pass\n",
    "                elif target in include:\n",
    "                    pass\n",
    "                else:\n",
    "                    continue\n",
    "                k += 1\n",
    "                if (k % 2) == 0:\n",
    "                    m = markers[0]\n",
    "                else:\n",
    "                    m = markers[1]\n",
    "                rd = results[benchmark][target][method][d]\n",
    "                targs.append(rd['Exp. {}'.format(d)])\n",
    "                preds.append(rd['Pred. {}'.format(d)])\n",
    "                try:\n",
    "                    sems.append(rd['CCC_Error'])\n",
    "                    error = 'CCC_Error'\n",
    "                except:\n",
    "                    sems.append(rd['SEM'])\n",
    "                    error = 'SEM'\n",
    "                if type == 'relat':\n",
    "                    ieb = ax[0].errorbar(x=rd['Exp. {}'.format(d)], y=rd['Pred. {}'.format(d)], yerr=rd[error], fmt='o', ecolor='grey', marker=m, alpha=0.20)\n",
    "                im = ax[0].scatter(x=rd['Exp. {}'.format(d)], y=rd['Pred. {}'.format(d)], edgecolors='black', s=75, marker=m, label=target)\n",
    "                if type == 'relat':\n",
    "                    for _, r in rd.iterrows():\n",
    "                        outfile.write('{},{},{},{},{}\\n'.format(r['Ligand_1'], r['Ligand_2'], round(r['Pred. ddG'], 3), r['Exp. ddG'], round(r['SEM'], 3)))\n",
    "                else:\n",
    "                    for _, r in rd.iterrows():\n",
    "                        outfile.write('{},{},{},{}\\n'.format(r['Ligand'], round(r['Pred. dG'], 3), r['Exp. dG'], round(r['CCC_Error'], 3)))\n",
    "    \n",
    "    targs =  [i for target in targs for i in target]\n",
    "    preds =  [i for target in preds for i in target]\n",
    "    sems =  [i for target in sems for i in target]\n",
    "    \n",
    "    ban_idx = []\n",
    "    for arr in [targs, preds, sems]:\n",
    "        nan_idx = [x for x in range(0, len(arr)) if np.isnan(arr[x])]\n",
    "        ban_idx.extend(nan_idx)\n",
    "        \n",
    "    targs = [j for i, j in enumerate(targs) if i not in ban_idx]\n",
    "    preds = [j for i, j in enumerate(preds) if i not in ban_idx]\n",
    "    sems = [j for i, j in enumerate(sems) if i not in ban_idx]\n",
    "    m = analysis(targs, preds, sems)\n",
    "    reg = [m['slope'] * x + m['intercept'] for x in np.arange(-18, 9, 1)]\n",
    "    ax[0].plot(np.arange(-18, 9, 1), reg, color='orange', linewidth=3)\n",
    "\n",
    "    if type == 'abs':\n",
    "        ax[1].annotate('y={}\\n +{}*x\\nR$^2$={}±{}\\nR={}±{}\\nN={}\\n\\u03C1={}\\n\\u03C4={}±{}\\nMAE={}±{}\\nRMSE={}±{}\\nPath_error={}±{}'.format(m[\"intercept\"],\n",
    "        m[\"slope\"], m[\"r2\"][0], m[\"r2\"][1], m[\"r\"][0], m[\"r\"][1], m[\"n\"], m[\"sp_rho\"], m[\"k_tau\"][0], m[\"k_tau\"][1], m[\"MAE\"][0], m['MAE'][1], m[\"RMSE\"][0], m[\"RMSE\"][1], m[\"SEM\"][0], m[\"SEM\"][1]), xy=(0, 0.25), size=22, bbox=dict(boxstyle=\"round\", fc=(0.8, 0.6, 0.2)))\n",
    "    if type == 'relat':\n",
    "        ax[1].annotate('y={}\\n +{}*x\\nR$^2$={}±{}\\nR={}±{}\\nN={}\\n\\u03C1={}\\n\\u03C4={}±{}\\nMAE={}±{}\\nRMSE={}±{}\\nMCC={}±{}\\nCCC_error={}±{}'.format(m[\"intercept\"],\n",
    "        m[\"slope\"], m[\"r2\"][0], m[\"r2\"][1], m[\"r\"][0], m[\"r\"][1], m[\"n\"], m[\"sp_rho\"], m[\"k_tau\"][0], m[\"k_tau\"][1],\n",
    "        m[\"MAE\"][0], m['MAE'][1], m[\"RMSE\"][0], m[\"RMSE\"][1], m[\"MCC\"][0], m[\"MCC\"][1],\n",
    "        m[\"SEM\"][0], m[\"SEM\"][1]), xy=(0, 0.125), size=22, bbox=dict(boxstyle=\"round\", fc=(0.8, 0.6, 0.2)))\n",
    "    ax[0].legend(loc=4)\n",
    "    ax[0].grid(alpha=0.3)\n",
    "    plt.savefig('plots/linreg_{}_{}.png'.format(d, method), dpi=300)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in method you can try: 'cresset_valid', 'amber', 'gaff', 'cgenff', 'consensus', FEP+_5ns\n",
    "# also\n",
    "# 'OPLS2015', openFF', 'openFF2' (QligFEP),,.s\n",
    "\n",
    "#Merck -> #'cdk8', 'cmet', 'eg5', 'hif2a', 'pfkfb3', 'shp2', 'syk', 'tnks2'\n",
    "#JACS -> #'BACE', 'CDK2', 'JNK1', 'MCL1', 'PTP1B', 'Thrombin', 'Tyk2', 'p38'\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "linplot(include=['BACE'], d='ddG', method='OPLS2015')\n",
    "#linplot(include=['BACE', 'CDK2', 'JNK1', 'MCL1', 'PTP1B', 'Thrombin', 'Tyk2', 'p38', 'cdk8', 'cmet', 'eg5', 'hif2a', 'pfkfb3', 'shp2', 'syk', 'tnks2'], d='ddG', method='OPLS2015')\n",
    "#linplot(include=['BACE', 'CDK2', 'JNK1', 'MCL1', 'PTP1B', 'Thrombin', 'Tyk2', 'p38'], d='dG', method='OPLS2015')\n",
    "linplot(include=['cdk8', 'cmet', 'eg5', 'hif2a', 'pfkfb3', 'shp2', 'syk', 'tnks2'], d='dG', method='FEP+_5ns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tables/Barplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def barplot(d, metric):\n",
    "    c = plt.cm.Set1(np.linspace(0,1,8))\n",
    "    fig = plt.figure(figsize=(24, 8), facecolor='white')\n",
    "    axes = fig.subplots(nrows=2, ncols=8)\n",
    "    #fig.suptitle('JACS & Merck benchmarks - QligFEP {} results'.format(d), size=24)\n",
    "    performance = []\n",
    "\n",
    "    with open('plots/{}_{}_barplot_data.txt'.format(d, metric), 'w') as outfile:\n",
    "        for i, target in enumerate(['BACE', 'CDK2', 'JNK1', 'MCL1', 'PTP1B', 'Thrombin', 'Tyk2', 'p38', 'CDK8', 'cMET', 'EG5', 'HIF2A', 'PFKFB3', 'SHP2', 'SYK', 'TNKS2']):\n",
    "            if i < 8:\n",
    "                benchmark = 'JACS'\n",
    "                y = 0\n",
    "            else:\n",
    "                benchmark = 'Merck'\n",
    "                y = 1\n",
    "            means = []\n",
    "            stdev = []\n",
    "            for method in ['OPLS2015', 'openFF', 'openFF2', 'FEP+_5ns']:\n",
    "                try:\n",
    "                    r = results[benchmark][target][method][d]    \n",
    "                except:\n",
    "                    r = results[benchmark][target.lower()][method][d]    \n",
    "                if i >= 8:\n",
    "                    i = i - 8\n",
    "                try:\n",
    "                    m = analysis(r['Exp. {}'.format(d)], r['Pred. {}'.format(d)], r['CCC_Error'])\n",
    "                except:\n",
    "                    m = analysis(r['Exp. {}'.format(d)], r['Pred. {}'.format(d)], r['SEM'])\n",
    "                if method == 'OPLS2015':\n",
    "                    performance.append((m[metric][0], m[metric][1], target))\n",
    "                means.append(m[metric][0])\n",
    "                stdev.append(m[metric][1])\n",
    "                outfile.write('{} - {} - {}±{}\\n'.format(method, target, m[metric][0], m[metric][1]))\n",
    "            title = target\n",
    "            axes[y, i].bar([0, 1, 2, 3], means, yerr=stdev, color=c, zorder=3, capsize=5, width=1.0, edgecolor='black')\n",
    "            \n",
    "            axes[y, i].set_title(title)\n",
    "            axes[y, i].set_ylim(0, 2.5)\n",
    "            axes[y, i].set_yticks(np.arange(0.5, 2.5, 0.5))\n",
    "            axes[y, i].set_xticks([])\n",
    "            axes[y, i].grid(zorder=0)\n",
    "    \n",
    "    from matplotlib.lines import Line2D\n",
    "    #fig.text(0.075, 0.25, 'RMSE (kcal/mol)', rotation='vertical', size=30)\n",
    "    legend_elements = [Line2D([0], [0], color=c[0], lw=7, label='OPLS2015'),\n",
    "                        Line2D([0], [0], color=c[1], lw=7, label='openFF'),\n",
    "                        Line2D([0], [0], color=c[2], lw=7, label='openFF2'),\n",
    "                        Line2D([0], [0], color=c[3], lw=7, label='FEP+_5ns')]\n",
    "    fig.legend(handles=legend_elements,\n",
    "            labels=['OPLS2015', 'openFF', 'openFF2', 'OPLS2.1/OPLS3e'],   # The labels for each line\n",
    "            loc=\"right\",   # Position of legend\n",
    "            title=\"Forcefield\", # Title for the legend\n",
    "            fontsize=12.5\n",
    "            ) \n",
    "    plt.savefig('plots/Barplots_{}.png'.format(d), dpi=1000)\n",
    "    plt.show()\n",
    "    return performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = barplot(d='ddG', metric='MAE')\n",
    "\n",
    "#If you want to recalculate with bootstrapping the overall performance for the \n",
    "# a desired metric\n",
    "\n",
    "performance = performance[:8] #JACS only\n",
    "#performance = performance[8:] #Merck only\n",
    "#performance = performance #All together\n",
    "\n",
    "import random\n",
    "means = []\n",
    "for i in np.arange(10000):\n",
    "    sample = random.choices(performance, k=round(len(performance)*0.90))\n",
    "    means.append(np.mean([x for x, y, z in sample]))\n",
    "    \n",
    "print('Average mean {} and standard deviation {}'.format(np.mean(means), np.std(means)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(metric, method, dataset):\n",
    "    performance = []\n",
    "    if dataset == 'All':\n",
    "        #cresset_valid schrodinger\tamber\tgaff\tcgenff\tconsensus\n",
    "        for target in ['BACE', 'CDK2', 'JNK1', 'MCL1', 'PTP1B', 'Thrombin', 'Tyk2', 'p38']:   \n",
    "            dt = pd.read_excel('{}/results/final_results_all.xlsx'.format(os.getcwd()), engine='openpyxl', sheet_name='{}'.format(target))\n",
    "            m = analysis(dt['dGexptl'][:-1], dt[method][:-1], np.zeros(len(dt['dGexptl']) - 1))\n",
    "            performance.append((m[metric][0], m[metric][1], target))\n",
    "    else:\n",
    "        dt = pd.read_excel('{}/results/final_results_all.xlsx'.format(os.getcwd()), engine='openpyxl', sheet_name='{}'.format(dataset))\n",
    "        m = analysis(dt['dGexptl'][:-1], dt[method][:-1], np.zeros(len(dt['dGexptl']) - 1))\n",
    "        performance.append((m[metric][0], m[metric][1], dataset))\n",
    "    return performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If you want to calculate the dG metrics for any of the following 'methods'\n",
    "# cresset_valid schrodinger\tamber\tgaff\tcgenff\tconsensus with bootstrapping\n",
    "import random\n",
    "performance = get_results('MAE', 'schrodinger', 'All')\n",
    "means = []\n",
    "for i in np.arange(10000):\n",
    "    sample = random.choices(performance[:8], k=round(len(performance[:8])*0.90))\n",
    "    means.append(np.mean([x for x, y, z in sample]))\n",
    "    \n",
    "print('Average mean {} and standard deviation {}'.format(np.mean(means), np.std(means)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select random perturbations with low error, where QligFEP is able to capture both the right direction and magnitude. Might be useful for choosing perturbations for the figures of the manuscript."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff = 'OPLS2015'\n",
    "low_error = []\n",
    "for benchmark in results.keys():\n",
    "    for target in results[benchmark].keys():\n",
    "        r = results[benchmark][target][ff]['ddG']\n",
    "        r['target'] = target\n",
    "        r['benchmark'] = benchmark\n",
    "        low_error.append(r[r['error'].between(-1,1)])\n",
    "\n",
    "low_error_perturbations = pd.concat(low_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_error_perturbations.query('-1 < error < 1 & benchmark == \"JACS\"').sample(n = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_error_perturbations.query('-1 < error < 1 & benchmark == \"Merck\"').sample(n = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f4ead7ca1e9c4ac07e5ad9b915f23dfe267673a27994605916c65c767257898c"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
